# Evaluation Configuration
# Configuration for model evaluation and validation gates

evaluation:
  # Metrics to compute
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "roc_auc"
  
  # Threshold gates (PR-blocking if not met)
  thresholds:
    accuracy: 0.85
    f1: 0.90
    precision: 0.88
    recall: 0.88
  
  # Regression detection
  regression_check:
    enabled: true
    baseline_metrics_path: "reports/baseline_metrics.json"
    significance_level: 0.05
    tolerance: 0.02  # Allow 2% degradation
  
  # Additional checks
  calibration_check:
    enabled: false
    method: "platt"
  
  robustness_check:
    enabled: false
    perturbation_level: 0.1
  
  # Reporting
  generate_confusion_matrix: true
  generate_plots: true
  output_format: ["json", "markdown"]
